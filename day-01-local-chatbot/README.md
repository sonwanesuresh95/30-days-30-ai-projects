# ğŸ¤– Day 1 â€” Local Chatbot with Ollama + LLaMA

![Python](https://img.shields.io/badge/Python-3.12-blue)
![Ollama](https://img.shields.io/badge/Ollama-Enabled-green)
![LLaMA](https://img.shields.io/badge/LLaMA-3.1-orange)
![License](https://img.shields.io/badge/License-MIT-purple)

> ğŸš€ **A blazing-fast, local AI chatbot** powered by [Ollama](https://ollama.com) and **LLaMA** models.

---

## âœ¨ Features
- ğŸ’¬ Chat with LLaMA 3.1 locally
- âš¡ Uses **Ollama** for optimized model loading
- ğŸ”§ Easy to configure via `.env`
- ğŸ³ Docker support out-of-the-box

---

## ğŸš€ Quickstart

1ï¸âƒ£ **Install Ollama**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

2ï¸âƒ£ **Pull a model** (example: `llama3:8b`)
```bash
ollama pull llama3:8b
```

3ï¸âƒ£ **Edit environment variables**
```bash
nano .env
```

4ï¸âƒ£ **Install dependencies**
```bash
poetry install
```

5ï¸âƒ£ **Run the chatbot**
```bash
python -m src.chatbot.main
# Or with Docker
docker compose up --build
```

---

## ğŸ“¸ Screenshot
![Chat Screenshot](https://via.placeholder.com/800x400?text=Chatbot+Demo)

---

## ğŸ“œ License
This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---